{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "976f1fff"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def clean_employee_records(input_file, output_file, handle_missing_id='generate'):\n",
        "\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(input_file)\n",
        "\n",
        "    # 1. Remove duplicate rows (keeping first occurrence)\n",
        "    df_clean = df.drop_duplicates()\n",
        "\n",
        "    # 2. Handle missing EmployeeIDs based on user preference\n",
        "    missing_id_mask = df_clean['EmployeeID'].isna() | (df_clean['EmployeeID'] == '')\n",
        "\n",
        "    if handle_missing_id == 'drop':\n",
        "        df_clean = df_clean[~missing_id_mask]\n",
        "    elif handle_missing_id == 'generate':\n",
        "        # Find the highest existing EmployeeID number\n",
        "        existing_ids = df_clean['EmployeeID'].dropna()\n",
        "        numeric_parts = [int(id[1:]) for id in existing_ids if id != '' and id[1:].isdigit()]\n",
        "        next_id_num = max(numeric_parts) + 1 if numeric_parts else 1\n",
        "\n",
        "        # Generate new IDs for rows with missing EmployeeID\n",
        "        for idx in df_clean[missing_id_mask].index:\n",
        "            df_clean.at[idx, 'EmployeeID'] = f\"E{next_id_num:03d}\"\n",
        "            next_id_num += 1\n",
        "    elif handle_missing_id == 'keep':\n",
        "        pass\n",
        "\n",
        "    # 3. Clean Salary - handle missing values and ensure numeric format\n",
        "    df_clean['Salary($)'] = df_clean['Salary($)'].replace('', np.nan)\n",
        "    df_clean['Salary($)'] = pd.to_numeric(df_clean['Salary($)'], errors='coerce')\n",
        "\n",
        "    # Calculate mean salary (excluding missing values)\n",
        "    mean_salary = df_clean['Salary($)'].mean()\n",
        "\n",
        "    # Fill missing salaries with mean salary\n",
        "    df_clean['Salary($)'] = df_clean['Salary($)'].fillna(mean_salary)\n",
        "\n",
        "    # 4. Clean Department - fill missing values with 'Unknown'\n",
        "    df_clean['Department'] = df_clean['Department'].fillna('Unknown')\n",
        "    df_clean['Department'] = df_clean['Department'].replace('', 'Unknown')\n",
        "\n",
        "    # 5. Clean JoinDate - standardize date format and handle missing values\n",
        "    def parse_date(date_str):\n",
        "        if pd.isna(date_str) or date_str == '':\n",
        "            return np.nan\n",
        "\n",
        "        formats = ['%Y-%m-%d', '%Y/%m/%d', '%d-%m-%Y', '%d/%m/%Y']\n",
        "\n",
        "        for fmt in formats:\n",
        "            try:\n",
        "                return datetime.strptime(str(date_str), fmt)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        return np.nan\n",
        "\n",
        "    # Parse dates first (returns datetime objects)\n",
        "    df_clean['JoinDate_parsed'] = df_clean['JoinDate'].apply(parse_date)\n",
        "\n",
        "    # Calculate mean date (excluding missing values)\n",
        "    date_timestamps = df_clean['JoinDate_parsed'].dropna().apply(lambda x: x.timestamp())\n",
        "    mean_timestamp = date_timestamps.mean()\n",
        "\n",
        "    if not pd.isna(mean_timestamp):\n",
        "        mean_date = datetime.fromtimestamp(mean_timestamp)\n",
        "        # Fill missing dates with mean date\n",
        "        df_clean['JoinDate_parsed'] = df_clean['JoinDate_parsed'].fillna(mean_date)\n",
        "\n",
        "    # Convert back to string format for final output\n",
        "    df_clean['JoinDate'] = df_clean['JoinDate_parsed'].apply(\n",
        "        lambda x: x.strftime('%Y-%m-%d') if pd.notna(x) else np.nan\n",
        "    )\n",
        "\n",
        "    # Drop the temporary parsed column\n",
        "    df_clean = df_clean.drop('JoinDate_parsed', axis=1)\n",
        "\n",
        "    # 6. Reset index after cleaning\n",
        "    df_clean = df_clean.reset_index(drop=True)\n",
        "\n",
        "    # 7. Save cleaned data to new CSV file\n",
        "    df_clean.to_csv(output_file, index=False)\n",
        "\n",
        "    return df_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a462d34"
      },
      "outputs": [],
      "source": [
        "# Usage example:\n",
        "if __name__ == \"__main__\":\n",
        "    cleaned_df = clean_employee_records('employee_records_dirty.csv', 'employee_records_clean.csv', 'generate')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
